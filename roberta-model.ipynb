{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9870740,"sourceType":"datasetVersion","datasetId":5992648},{"sourceId":10055508,"sourceType":"datasetVersion","datasetId":6195743},{"sourceId":10055802,"sourceType":"datasetVersion","datasetId":5900835},{"sourceId":10058569,"sourceType":"datasetVersion","datasetId":6198303}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T10:00:10.098765Z","iopub.execute_input":"2024-11-30T10:00:10.099538Z","iopub.status.idle":"2024-11-30T10:00:44.088423Z","shell.execute_reply.started":"2024-11-30T10:00:10.099506Z","shell.execute_reply":"2024-11-30T10:00:44.087400Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"L0lcDQnD9id9"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Set up"],"metadata":{"id":"7glDbHaT9ieE"}},{"cell_type":"code","source":["# First cell - Imports and Setup\n","import os\n","import torch\n","import pandas as pd\n","import numpy as np\n","from tqdm.notebook import tqdm\n","import gc\n","import json\n","import zipfile\n","from sklearn.model_selection import train_test_split, KFold\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import RobertaTokenizer, RobertaModel, get_cosine_schedule_with_warmup, set_seed\n","from torch import nn\n","from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from torch.cuda.amp import autocast, GradScaler\n","import warnings\n","import random\n","warnings.filterwarnings('ignore')"],"metadata":{"execution":{"iopub.status.busy":"2024-11-30T11:26:14.433409Z","iopub.execute_input":"2024-11-30T11:26:14.433836Z","iopub.status.idle":"2024-11-30T11:26:14.441535Z","shell.execute_reply.started":"2024-11-30T11:26:14.433779Z","shell.execute_reply":"2024-11-30T11:26:14.440239Z"},"trusted":true,"id":"DAd-hS0P9ieH"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# Configure PyTorch memory allocation\n","os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:32'\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","if torch.cuda.is_available():\n","    print(f\"GPU Memory Available: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n","\n","def set_seed(seed=42):\n","    \"\"\"Set all random seeds for reproducibility\"\"\"\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)"],"metadata":{"execution":{"iopub.status.busy":"2024-11-30T11:26:15.122874Z","iopub.execute_input":"2024-11-30T11:26:15.123192Z","iopub.status.idle":"2024-11-30T11:26:15.129347Z","shell.execute_reply.started":"2024-11-30T11:26:15.123164Z","shell.execute_reply":"2024-11-30T11:26:15.128328Z"},"trusted":true,"id":"5miYtZQb9ieI"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["class SarcasmTextDataset(Dataset):\n","    def __init__(self, df, tokenizer, max_length=128):\n","        self.df = df\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        text = f\"{row['caption']} {row['emojis']} {row['emoji_explain']}\"\n","\n","        encoding = self.tokenizer(\n","            text,\n","            padding=\"max_length\",\n","            truncation=True,\n","            max_length=self.max_length,\n","            return_tensors=\"pt\"\n","        )\n","\n","        encoding = {k: v.squeeze() for k, v in encoding.items()}\n","        encoding['labels'] = torch.tensor(row['label'], dtype=torch.long)\n","        return encoding\n"],"metadata":{"execution":{"iopub.status.busy":"2024-11-30T11:26:15.679531Z","iopub.execute_input":"2024-11-30T11:26:15.679776Z","iopub.status.idle":"2024-11-30T11:26:15.685753Z","shell.execute_reply.started":"2024-11-30T11:26:15.679752Z","shell.execute_reply":"2024-11-30T11:26:15.684855Z"},"trusted":true,"id":"BAUtuYke9ieJ"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# define hyperparameter\n","hidden_size = 512\n","num_labels = 2\n","batch_size = 128\n","num_epochs = 3\n","l_r = 2e-5"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T12:14:08.997903Z","iopub.execute_input":"2024-11-30T12:14:08.998261Z","iopub.status.idle":"2024-11-30T12:14:09.002706Z","shell.execute_reply.started":"2024-11-30T12:14:08.998232Z","shell.execute_reply":"2024-11-30T12:14:09.001744Z"},"id":"Upp5yLB49ieK"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# Text Sarcasm Classifier\n","class TextSarcasmClassifier(nn.Module):\n","    def __init__(self, hidden_size, num_labels):\n","        super().__init__()\n","        self.roberta = RobertaModel.from_pretrained(\"roberta-base\")\n","        self.classifier = nn.Sequential(\n","            nn.Linear(self.roberta.config.hidden_size, hidden_size),  # Increased layer size\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","\n","            nn.Linear(hidden_size, hidden_size // 2),  # Additional layer\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","\n","            nn.Linear(hidden_size // 2, num_labels)  # Ensure correct output size\n","        )\n","\n","    def forward(self, input_ids, attention_mask=None):\n","        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n","        cls_token = outputs.last_hidden_state[:, 0, :]  # CLS token\n","        logits = self.classifier(cls_token)\n","        probabilities = nn.functional.softmax(logits, dim=1)\n","        return probabilities"],"metadata":{"execution":{"iopub.status.busy":"2024-11-30T12:14:09.472319Z","iopub.execute_input":"2024-11-30T12:14:09.472943Z","iopub.status.idle":"2024-11-30T12:14:09.479039Z","shell.execute_reply.started":"2024-11-30T12:14:09.472909Z","shell.execute_reply":"2024-11-30T12:14:09.478102Z"},"trusted":true,"id":"CHuLQ43t9ieK"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["class EarlyStopping:\n","    def __init__(self, patience=3, min_delta=0):\n","        self.patience = patience\n","        self.min_delta = min_delta\n","        self.counter = 0\n","        self.best_loss = None\n","        self.early_stop = False\n","\n","    def __call__(self, val_loss):\n","        if self.best_loss is None:\n","            self.best_loss = val_loss\n","        elif val_loss > self.best_loss - self.min_delta:\n","            self.counter += 1\n","            if self.counter >= self.patience:\n","                return True\n","        else:\n","            self.best_loss = val_loss\n","            self.counter = 0\n","        return False"],"metadata":{"execution":{"iopub.status.busy":"2024-11-30T12:14:09.944473Z","iopub.execute_input":"2024-11-30T12:14:09.945034Z","iopub.status.idle":"2024-11-30T12:14:09.949992Z","shell.execute_reply.started":"2024-11-30T12:14:09.945004Z","shell.execute_reply":"2024-11-30T12:14:09.949233Z"},"trusted":true,"id":"l9HGqf_x9ieL"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["def train_epoch(model, dataloader, optimizer, scheduler, criterion, device):\n","    model.train()\n","    total_loss = 0\n","    predictions = []\n","    true_labels = []\n","\n","    # Thêm tqdm để theo dõi tiến trình\n","    progress_bar = tqdm(dataloader, desc='Training')\n","\n","    for batch in progress_bar:\n","        try:\n","            # Clear cache nếu cần\n","            if torch.cuda.is_available():\n","                torch.cuda.empty_cache()\n","\n","            # Move data to device\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            # Forward pass với gradient scaling\n","            with autocast():\n","                outputs = model(input_ids, attention_mask)\n","                loss = criterion(outputs, labels)\n","\n","\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","            if scheduler is not None:\n","                scheduler.step()\n","\n","            # Collect metrics\n","            total_loss += loss.item()\n","            predictions.extend(outputs.argmax(dim=1).cpu().numpy())\n","            true_labels.extend(labels.cpu().numpy())\n","\n","            # Update progress bar\n","            progress_bar.set_postfix({'loss': loss.item()})\n","\n","        except Exception as e:\n","            print(f\"Error in batch: {str(e)}\")\n","            continue\n","\n","\n","\n","    # Convert lists to numpy arrays for sklearn metrics\n","    predictions = np.array(predictions)\n","    true_labels = np.array(true_labels)\n","    cm = confusion_matrix(true_labels, predictions)\n","    # Calculate metrics\n","    metrics = {\n","        'loss': total_loss / len(dataloader),\n","        'accuracy': accuracy_score(true_labels, predictions),\n","        'f1_score': f1_score(true_labels, predictions, average='weighted'),\n","        'precision': precision_score(true_labels, predictions, average='weighted'),\n","        'recall': recall_score(true_labels, predictions, average='weighted'),\n","        'confusion_matrix': cm\n","    }\n","\n","    return metrics"],"metadata":{"execution":{"iopub.status.busy":"2024-11-30T12:14:10.319864Z","iopub.execute_input":"2024-11-30T12:14:10.320159Z","iopub.status.idle":"2024-11-30T12:14:10.329129Z","shell.execute_reply.started":"2024-11-30T12:14:10.320134Z","shell.execute_reply":"2024-11-30T12:14:10.328240Z"},"trusted":true,"id":"zCQVUlW29ieM"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["\n","def validate(model, dataloader, criterion, device):\n","    model.eval()\n","    total_loss = 0\n","    all_preds = []\n","    all_labels = []\n","    all_probabilities = []\n","\n","    with torch.no_grad():\n","        for batch in tqdm(dataloader, desc=\"Validating\"):\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","            # Tính xác suất\n","            probabilities = torch.softmax(outputs, dim=1)\n","\n","            loss = criterion(outputs, labels)\n","\n","            total_loss += loss.item()\n","            predictions = outputs.argmax(-1)\n","\n","            all_preds.extend(predictions.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","            all_probabilities.extend(probabilities.cpu().numpy())\n","\n","    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\n","    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n","    cm = confusion_matrix(all_labels, all_preds)\n","\n","#     plt.figure(figsize=(8, 6))\n","#     sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n","#     plt.title('Confusion Matrix')\n","#     plt.ylabel('True Label')\n","#     plt.xlabel('Predicted Label')\n","#     plt.show()\n","\n","    metrics = {\n","        'loss': total_loss / len(dataloader),\n","        'accuracy': accuracy,\n","        'precision': precision,\n","        'recall': recall,\n","        'f1_score': f1,\n","        'confusion_matrix': cm,\n","        'probabilities': all_probabilities,\n","        'labels': all_labels\n","    }\n","\n","    return metrics\n","\n","def print_metrics(phase, metrics):\n","    print(f\"\\n{phase} Metrics:\")\n","    print(f\"Loss: {metrics['loss']:.4f}\")\n","    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n","    print(f\"F1-Score: {metrics['f1_score']:.4f}\")\n","    print(f\"Precision: {metrics['precision']:.4f}\")\n","    print(f\"Recall: {metrics['recall']:.4f}\")\n","    # Thêm try-except để xử lý trường hợp không có confusion matrix\n","    try:\n","        plt.figure(figsize=(8, 6))\n","        sns.heatmap(metrics['confusion_matrix'], annot=True, fmt='d', cmap='Blues')\n","        plt.title(f'{phase} Confusion Matrix')  # Thêm phase vào title\n","        plt.ylabel('True Label')\n","        plt.xlabel('Predicted Label')\n","        plt.show()\n","    except KeyError:\n","        print(\"Warning: Confusion matrix not found in metrics\")"],"metadata":{"execution":{"iopub.status.busy":"2024-11-30T12:14:10.680941Z","iopub.execute_input":"2024-11-30T12:14:10.681542Z","iopub.status.idle":"2024-11-30T12:14:10.690728Z","shell.execute_reply.started":"2024-11-30T12:14:10.681515Z","shell.execute_reply":"2024-11-30T12:14:10.689829Z"},"trusted":true,"id":"KSimwjif9ieO"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["def cross_validation_train(df, n_splits=3, test_size=0.15,\n","                      hidden_size=hidden_size,\n","                      epochs=num_epochs, batch_size=batch_size,\n","                      learning_rate=l_r,\n","                      temperature=2.0,\n","                      clip_value=1.0):\n","    tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n","    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n","\n","    # Split the dataset into train/validation and test sets\n","    train_val_df, test_df = train_test_split(df, test_size=test_size, random_state=42, stratify=df['label'])\n","\n","    fold_results = []\n","    all_val_labels = []  # To store validation labels\n","    early_stopping = EarlyStopping(patience=3, min_delta=0.001)\n","\n","    for fold, (train_idx, val_idx) in enumerate(kfold.split(train_val_df)):\n","        print(f\"\\nTraining Fold {fold + 1}/{n_splits}\")\n","\n","        train_data = train_val_df.iloc[train_idx].reset_index(drop=True)\n","        val_data = train_val_df.iloc[val_idx].reset_index(drop=True)\n","\n","        # Store validation labels\n","        all_val_labels.append(val_data['label'].values)\n","\n","        # Create test dataset and dataloader once\n","        test_dataset = SarcasmTextDataset(test_df, tokenizer)\n","        test_loader = DataLoader(\n","            test_dataset,\n","            batch_size=batch_size,\n","            num_workers=4,\n","            pin_memory=True\n","        )\n","\n","        # Create datasets and dataloaders\n","        train_dataset = SarcasmTextDataset(train_data, tokenizer)\n","        val_dataset = SarcasmTextDataset(val_data, tokenizer)\n","\n","        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","        # Initialize model\n","        model = TextSarcasmClassifier(hidden_size, num_labels).to(device)\n","\n","        # AdamW optimizer with weight decay and gradient clipping\n","        optimizer = torch.optim.AdamW(\n","            model.parameters(),\n","            lr=learning_rate,\n","            weight_decay=0.01\n","        )\n","\n","        # Loss function without class weights\n","        criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n","\n","        # Learning rate scheduler with warmup\n","        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n","            optimizer,\n","            max_lr=learning_rate,\n","            epochs=epochs,\n","            steps_per_epoch=len(train_loader),\n","            pct_start=0.3,  # 30% epochs for warmup\n","            anneal_strategy='linear'\n","        )\n","\n","        best_val_f1 = 0\n","        for epoch in range(epochs):\n","            print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n","\n","            train_metrics = train_epoch(model, train_loader, optimizer, scheduler, criterion, device)\n","            val_metrics = validate(model, val_loader, criterion, device)\n","\n","            if val_metrics['accuracy'] > best_val_f1:\n","                best_val_f1 = val_metrics['accuracy']\n","                torch.save({\n","                    'fold': fold,\n","                    'epoch': epoch,\n","                    'model_state_dict': model.state_dict(),\n","                    'optimizer_state_dict': optimizer.state_dict(),\n","                    'metrics': val_metrics,\n","                    'probabilities': val_metrics['probabilities'],\n","                    'val_labels': val_metrics['labels'],\n","                }, f'best_model_fold_{fold}_epoch_{epoch}.pt')\n","\n","            if early_stopping(val_metrics['loss']):\n","                print(\"Early stopping triggered\")\n","                break\n","\n","        final_val_metrics = validate(model, val_loader, criterion, device)\n","        test_metrics = validate(model, test_loader, criterion, device)\n","\n","        fold_results.append({\n","            'fold': fold,\n","            'val_metrics': final_val_metrics,\n","            'test_metrics': test_metrics\n","        })\n","\n","        # Clear memory\n","        del model, optimizer, scheduler, train_loader, val_loader\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","\n","    # Print average results across folds\n","    print(\"\\nCross-validation Results:\")\n","\n","    # Calculate average validation metrics\n","    avg_val_metrics = {\n","        'accuracy': np.mean([r['val_metrics']['accuracy'] for r in fold_results]),\n","        'f1_score': np.mean([r['val_metrics']['f1_score'] for r in fold_results]),\n","        'precision': np.mean([r['val_metrics']['precision'] for r in fold_results]),\n","        'recall': np.mean([r['val_metrics']['recall'] for r in fold_results])\n","    }\n","\n","    # Calculate average test metrics\n","    avg_test_metrics = {\n","        'accuracy': np.mean([r['test_metrics']['accuracy'] for r in fold_results]),\n","        'f1_score': np.mean([r['test_metrics']['f1_score'] for r in fold_results]),\n","        'precision': np.mean([r['test_metrics']['precision'] for r in fold_results]),\n","        'recall': np.mean([r['test_metrics']['recall'] for r in fold_results])\n","    }\n","\n","    print(\"\\nValidation Metrics:\")\n","    print(f\"Average Accuracy: {avg_val_metrics['accuracy']:.4f}\")\n","    print(f\"Average F1-Score: {avg_val_metrics['f1_score']:.4f}\")\n","    print(f\"Average Precision: {avg_val_metrics['precision']:.4f}\")\n","    print(f\"Average Recall: {avg_val_metrics['recall']:.4f}\")\n","\n","    print(\"\\nTest Metrics:\")\n","    print(f\"Average Accuracy: {avg_test_metrics['accuracy']:.4f}\")\n","    print(f\"Average F1-Score: {avg_test_metrics['f1_score']:.4f}\")\n","    print(f\"Average Precision: {avg_test_metrics['precision']:.4f}\")\n","    print(f\"Average Recall: {avg_test_metrics['recall']:.4f}\")\n","\n","    return fold_results, avg_val_metrics, avg_test_metrics\n"],"metadata":{"execution":{"iopub.status.busy":"2024-11-30T12:14:11.042138Z","iopub.execute_input":"2024-11-30T12:14:11.042682Z","iopub.status.idle":"2024-11-30T12:14:11.059822Z","shell.execute_reply.started":"2024-11-30T12:14:11.042651Z","shell.execute_reply":"2024-11-30T12:14:11.058825Z"},"trusted":true,"id":"3h-Im2_19ieQ"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","\n","    # Configure paths\n","#     TEXT_DIR = \"/kaggle/input/vimmsd-uit/UIT/IT/datasets/input/train/training-images/train-images/\"\n","#     TRAIN_DATA_PATH = \"/kaggle/input/vimmsd-uit/train_data_2.csv\"\n","    # Load data/\n","    df = pd.read_csv('/kaggle/input/approach-2/text_data.csv')\n","    # Set random seed\n","    set_seed(42)\n","\n","    # Train model\n","    fold_results, val_metrics, test_metrics = cross_validation_train(\n","    df,\n","    n_splits=3,\n","    test_size=0.15,  # có thể điều chỉnh tỉ lệ test\n","    epochs=3,\n","\n","    )\n","\n","    print(\"\\nTraining completed!\")\n","    print(f\"Final Test Metrics:\")\n","    print(f\"Accuracy: {test_metrics['accuracy']:.4f}\")\n","    print(f\"F1-Score: {test_metrics['f1_score']:.4f}\")\n","    print(f\"Precision: {test_metrics['precision']:.4f}\")\n","    print(f\"Recall: {test_metrics['recall']:.4f}\")"],"metadata":{"execution":{"iopub.status.busy":"2024-11-30T12:18:58.529242Z","iopub.execute_input":"2024-11-30T12:18:58.529591Z","iopub.status.idle":"2024-11-30T12:30:54.604127Z","shell.execute_reply.started":"2024-11-30T12:18:58.529558Z","shell.execute_reply":"2024-11-30T12:30:54.603142Z"},"trusted":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"yg46Krwd9ieS"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["md_1 = torch.load('/kaggle/working/best_model_fold_1_epoch_2.pt')\n","md_1['metrics']"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T12:36:20.706645Z","iopub.execute_input":"2024-11-30T12:36:20.707500Z","iopub.status.idle":"2024-11-30T12:36:21.805167Z","shell.execute_reply.started":"2024-11-30T12:36:20.707465Z","shell.execute_reply":"2024-11-30T12:36:21.804235Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"kduPzHUh9ieS"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Lấy test pred"],"metadata":{"id":"aqEPOGM29ieT"}},{"cell_type":"code","source":["# Dataset class cho public test\n","class SarcasmTestDataset(Dataset):\n","    def __init__(self, df, tokenizer, max_length=77):\n","        self.df = df\n","        self.max_length = max_length\n","        self.tokenizer = tokenizer\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def prepare_text(self, row):\n","        return str(row['caption']) if pd.notna(row['caption']) else ''\n","\n","    def __getitem__(self, idx):\n","        try:\n","            row = self.df.iloc[idx]\n","\n","            # Prepare text\n","            text = self.prepare_text(row)\n","\n","\n","            # Process inputs\n","            encoding = self.tokenizer(\n","                text=text,\n","                padding=\"max_length\",\n","                truncation=True,\n","                max_length=self.max_length,\n","                return_tensors=\"pt\"\n","            )\n","\n","            # Remove batch dimension\n","            for k, v in encoding.items():\n","                encoding[k] = v.squeeze()\n","\n","            # Thêm index và label nếu có\n","            encoding['index'] = torch.tensor(int(row['index']))\n","            if 'label' in row and pd.notna(row['label']):\n","                encoding['labels'] = torch.tensor(int(row['label']))\n","\n","            return encoding\n","\n","        except Exception as e:\n","            print(f\"Error processing index {idx}: {e}\")\n","            return None"],"metadata":{"execution":{"iopub.status.busy":"2024-11-30T12:36:53.131540Z","iopub.execute_input":"2024-11-30T12:36:53.132363Z","iopub.status.idle":"2024-11-30T12:36:53.139810Z","shell.execute_reply.started":"2024-11-30T12:36:53.132321Z","shell.execute_reply":"2024-11-30T12:36:53.138902Z"},"trusted":true,"id":"kBAzgHD69ieU"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["def evaluate_test_set(model, test_loader, device):\n","    model.eval()\n","    predictions = []\n","    indices = []\n","    true_labels = []\n","    probabilities = []\n","    with torch.no_grad():\n","        for batch in tqdm(test_loader, desc=\"Testing\"):\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","\n","            # Forward pass\n","            logits = model(\n","                input_ids=input_ids,\n","                attention_mask=attention_mask\n","            )\n","\n","            # Get predictions\n","            batch_preds = logits.argmax(-1).cpu().numpy()\n","            predictions.extend(batch_preds)\n","            indices.extend(batch['index'].cpu().numpy())\n","\n","            # Lưu xác suất dự đoán vào danh sách\n","            probabilities.extend(torch.softmax(logits, dim=-1).cpu().numpy())\n","\n","            # Nếu có nhãn thực tế, lưu lại\n","            if 'labels' in batch:\n","                true_labels.extend(batch['labels'].cpu().numpy())\n","\n","    return indices, predictions, true_labels, probabilities"],"metadata":{"execution":{"iopub.status.busy":"2024-11-30T12:36:54.148302Z","iopub.execute_input":"2024-11-30T12:36:54.148622Z","iopub.status.idle":"2024-11-30T12:36:54.155164Z","shell.execute_reply.started":"2024-11-30T12:36:54.148592Z","shell.execute_reply":"2024-11-30T12:36:54.154289Z"},"trusted":true,"id":"zHwh-XTs9ieU"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["def save_submission(predictions, probabilities, file_name='roberta_priv.pt'):\n","    \"\"\"\n","    Lưu trữ predictions và probabilities vào file .pt\n","    Args:\n","        predictions: list các predictions tương ứng\n","        probabilities: list các xác suất dự đoán tương ứng\n","        file_name: tên file để lưu trữ\n","    \"\"\"\n","    submission_data = {\n","        'predictions': predictions,\n","        'probabilities': probabilities\n","    }\n","    torch.save(submission_data, file_name)\n","    print(f\"Saved submission data to {file_name}\")"],"metadata":{"execution":{"iopub.status.busy":"2024-11-30T12:57:46.706869Z","iopub.execute_input":"2024-11-30T12:57:46.707250Z","iopub.status.idle":"2024-11-30T12:57:46.712636Z","shell.execute_reply.started":"2024-11-30T12:57:46.707216Z","shell.execute_reply":"2024-11-30T12:57:46.711736Z"},"trusted":true,"id":"5TlE9EV69ieU"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["def main_test():\n","    # Configuration\n","    BATCH_SIZE = 64\n","    #IMAGE_DIR = \"/kaggle/input/vimmsd-uit/UIT/IT/datasets/input/test/public-test-images/dev-images\"\n","    MODEL_PATH = \"/kaggle/working/best_model_fold_1_epoch_2.pt\"\n","\n","    # Load test data\n","    file = '/kaggle/input/private-set/vimmsd-private-test.json'\n","    with open(file) as data:\n","        dict_data = json.load(data)\n","\n","    test_df = pd.DataFrame.from_dict(dict_data, orient='index')\n","    test_df.reset_index(level=0, inplace=True)\n","    print(f\"Test samples: {len(test_df)}\")\n","\n","    test_df['index'] = pd.to_numeric(test_df['index'], errors='coerce').fillna(-1).astype(int)\n","    if 'label' in test_df.columns:\n","        test_df['label'] = pd.to_numeric(test_df['label'], errors='coerce').fillna(-1).astype(int)\n","\n","    print(test_df.dtypes)\n","\n","    # Initialize processor and model\n","    tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n","    model = TextSarcasmClassifier(hidden_size = 512, num_labels =2)\n","\n","    # Load trained model weights\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    checkpoint = torch.load(MODEL_PATH, map_location=device)\n","    model.load_state_dict(checkpoint['model_state_dict'], strict = False)\n","    model = model.to(device)\n","\n","    # Create test dataset and dataloader\n","    test_dataset = SarcasmTestDataset(test_df, tokenizer)\n","    test_loader = DataLoader(\n","        test_dataset,\n","        batch_size=BATCH_SIZE,\n","        shuffle=False,\n","        num_workers=2\n","    )\n","\n","    # Run evaluation\n","    indices, predictions, true_labels, probabilities = evaluate_test_set(model, test_loader, device)\n","\n","    # Lưu file submission chỉ với xác suất và nhãn dự đoán\n","    save_submission(predictions, probabilities)"],"metadata":{"execution":{"iopub.status.busy":"2024-11-30T12:59:14.544544Z","iopub.execute_input":"2024-11-30T12:59:14.544928Z","iopub.status.idle":"2024-11-30T12:59:14.553003Z","shell.execute_reply.started":"2024-11-30T12:59:14.544867Z","shell.execute_reply":"2024-11-30T12:59:14.552102Z"},"trusted":true,"id":"0oCP1-Nq9ieV"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    main_test()"],"metadata":{"execution":{"iopub.status.busy":"2024-11-30T12:59:16.768528Z","iopub.execute_input":"2024-11-30T12:59:16.769208Z","iopub.status.idle":"2024-11-30T12:59:24.538590Z","shell.execute_reply.started":"2024-11-30T12:59:16.769156Z","shell.execute_reply":"2024-11-30T12:59:24.537477Z"},"trusted":true,"id":"qx9v1wwR9ieV"},"outputs":[],"execution_count":null},{"cell_type":"code","source":[],"metadata":{"trusted":true,"id":"iWgYstK69ieV"},"outputs":[],"execution_count":null}]}